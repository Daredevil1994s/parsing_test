# parsing_test
# Анализ задачи по парсингу данных с сайта
## Что было сделано
Мы разработали скрипт на Python для парсинга цитат с сайта https://quotes.toscrape.com. Скрипт собирает текст цитаты, имя автора и теги, применённые к каждой цитате, и сохраняет их в формате JSON.
## Откуда были получены данные
Данные были получены с сайта https://quotes.toscrape.com, который представляет собой учебный ресурс для практики парсинга.
## Как осуществлялся сбор
Сбор данных осуществлялся с помощью библиотеки <code>requests</code> для отправки HTTP-запросов к сайту и библиотеки <code>BeautifulSoup</code> для анализа HTML-doc. Мы последовательно заходили на каждую страницу цитат, пока не достигли конца сайта, и извлекали нужные данные из HTML-кода страницы.
## Почему был выбран тот или иной метод/инструмент, а не другой
- <strong><code>requests</code></strong>: простой и удобный способ выполнения HTTP-запросов в Python.
- <strong><code>BeautifulSoup</code></strong>: эффективный инструмент для парсинга HTML и извлечения данных, который позволяет легко находить нужные элементы по тегам и классам.
- <strong>JSON</strong>: выбран для сохранения данных, так как это стандартный формат для обмена данными и сериализации структурированных данных.
